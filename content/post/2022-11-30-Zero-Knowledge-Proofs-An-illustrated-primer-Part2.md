---
showonlyimage: true
title:      "Zero Knowledge Proofs: An illustrated primer, PartÂ 2"
subtitle:   ""
# excerpt: "Zero Knowledge Proofs:An illustratedÂ primer"
description: "è®°å½•é˜…è¯»æ–‡ç« ã€ŠZero Knowledge Proofs: An illustrated primer, PartÂ 2ã€‹ç¬”è®°ã€‚"
date:       2022-11-30
author: Â  Â  "è°¢æ–‡è¿›"
image: "/img/2022-11-30-Zero-Knowledge-Proofs-An-illustrated-primer-Part2/background.jpg"
published: 2022-11-30 
tags:
    - ZKP
    - ç¬”è®° 

categories: [ ZKP ]
URL: "/2022/11/30/Zero-Knowledge-Proofs-An-illustrated-primer-Part2/"
---
åŸæ–‡é“¾æ¥ï¼š[Zero Knowledge Proofs: An illustrated primer, PartÂ 2](https://blog.cryptographyengineering.com/2017/01/21/zero-knowledge-proofs-an-illustrated-primer-part-2/)ã€‚è¿™ç¯‡åšå®¢é€šè¿‡Schnorråè®®è¯¦ç»†è®²è§£äº†é›¶çŸ¥è¯†è¯æ˜ä¸­çš„å®Œå¤‡æ€§ã€å¯é æ€§ä»¥åŠé›¶çŸ¥è¯†ï¼Œå¯¹äºå¼„æ‡‚æå–å™¨ã€æ¨¡æ‹Ÿå™¨ä»¥åŠé›¶çŸ¥è¯†ç­‰æ¦‚å¿µå¾ˆæœ‰å¸®åŠ©ã€‚ä¹‹å‰å¯¹äºæ¨¡æ‹Ÿå™¨çš„ä½œç”¨æœ‰äº›æ‡µæ‡µæ‡‚æ‡‚ï¼Œç°åœ¨çœ‹å®Œåæœ‰ä¸€ç§é€å½»çš„æ„Ÿè§‰ğŸ˜ƒã€‚

ğŸ“ æ€»ç»“ä¸€ä¸‹ï¼š

ä»»ä½•é›¶çŸ¥è¯†è¯æ˜å¿…é¡»æ»¡è¶³ä¸‰ä¸ªé‡è¦çš„æ€§è´¨ï¼š
1. å®Œå¤‡æ€§ã€‚ä»»ä½•è¯šå®çš„Proveræœ€ç»ˆéƒ½èƒ½å¤Ÿä½¿Verifierä¿¡æœã€‚
2. å¯é æ€§ã€‚å¦‚æœèƒ½è¯´æœVerifierï¼Œé‚£ä¹ˆä¸€å®šæœ‰å‘½é¢˜æ˜¯çœŸçš„ã€‚é€†å¦å‘½é¢˜å°±æ˜¯ï¼Œå¦‚æœå‘½é¢˜ä¸ä¸ºçœŸï¼Œé‚£ä¹ˆå°±ä¸èƒ½è¯´æœVerifierã€‚
3. é›¶çŸ¥è¯†ã€‚Verifieré™¤äº†çŸ¥é“å‘½é¢˜ä¸ºçœŸå¤–ä¸èƒ½è·å¾—å…¶ä»–ä»»ä½•ä¿¡æ¯ã€‚

å¦‚ä½•åœ¨è¯æ˜å¯é æ€§å’Œé›¶çŸ¥è¯†æ€§è´¨çš„åŒæ—¶åˆä¸ä¼šæ³„æ¼çŸ¥è¯†å‘¢ï¼Ÿç§˜è¯€å°±æ˜¯æ¨¡æ‹Ÿå™¨ï¼Œæ¨¡æ‹Ÿå™¨ä¸­æ‹¥æœ‰åœ¨å®é™…ä¸­ä¸å¯èƒ½æœ‰çš„è¶…èƒ½åŠ›ï¼Œæ¯”å¦‚è¯´æ—¶é—´æœºå™¨ã€‚è¿™æ ·å°±å¾ˆå·§å¦™çš„è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼

è¯æ˜å¯é æ€§ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå™¨ï¼å¯é æ€§è¯´çš„æ˜¯å¦‚æœèƒ½è¯´æœVerifierï¼Œé‚£ä¹ˆä¸€å®šæœ‰å‘½é¢˜ä¸ºçœŸã€‚åšå®¢ä¸­ä¸»è¦è®¨è®ºçš„"statement"æ˜¯ä¸ªäººçŸ¥è¯†è€Œä¸æ˜¯"facts"ï¼Œä¹Ÿå°±æ˜¯â€œæˆ‘çŸ¥é“æŸä¸ªçŸ¥è¯†ï¼Œæˆ–è€…è¯´ç§˜å¯†å§â€ã€‚å…·ä½“æ¥è®²ï¼Œå¯é æ€§å°±å˜æˆäº†ï¼Œå¦‚æœèƒ½è¯´æœVerifierï¼Œé‚£ä¹ˆProverä¸€å®šæ˜¯çŸ¥é“çŸ¥è¯†çš„ã€‚ä¸ºäº†è¯æ˜è¿™ä¸€ç‚¹ï¼Œæ¬å‡ºæå–å™¨çš„æ¦‚å¿µï¼Œæå–å™¨å……å½“Verifierçš„è§’è‰²ï¼Œå¯¹äºä»»ä½•å¯èƒ½çš„Proverï¼Œå¦‚æœéƒ½å­˜åœ¨ä¸€ä¸ªæå–å™¨èƒ½å¤Ÿæå–åˆ°çŸ¥è¯†ï¼Œé‚£ä¹ˆå°±è¯´æ˜Proverè‚¯å®šæ˜¯æœ‰çŸ¥è¯†çš„ã€‚è¿™ä¸å°±è¯æ˜äº†å¯é æ€§å˜›ï¼

é‚£é—®é¢˜æ˜¯æå–å™¨æ€ä¹ˆæå–çŸ¥è¯†å‘¢ï¼Ÿè®©æˆ‘ä»¬ä¸Šæ¨¡æ‹Ÿå™¨ä¸­çš„è¶…èƒ½åŠ›â€”â€”æ—¶å…‰æœºå™¨ï¼æå–å™¨èƒ½å¤Ÿå›æº¯ï¼Œè¾¾åˆ°éª—Proveråœ¨ä¸¤æ¬¡è¿è¡Œä¸­ä½¿ç”¨ç›¸åŒçš„éšæœºæ•°$k$ï¼Œç„¶åè®¡ç®—å‡ºProveråŸæ¥æ‹¥æœ‰çš„å¯†é’¥$a$ã€‚

è¯æ˜é›¶çŸ¥è¯†ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå™¨ï¼è¦è¯æ˜ç°å®ä¸­çš„Verifieré™¤äº†çŸ¥é“ProverçŸ¥é“çŸ¥è¯†è¿™ä¸€ç‚¹å¤–ä¸èƒ½è·å–åˆ°å…¶ä»–ä»»ä½•ä¿¡æ¯ï¼Œæˆ‘ä»¬æ„é€ ä¸€ä¸ªå‹æ ¹å°±ä¸çŸ¥é“å¯†é’¥$a$çš„Proverï¼Œå®ƒå’Œè¯šå®çš„Verifieräº¤äº’ï¼Œè®©Verifierç›¸ä¿¡Proveræ˜¯çŸ¥é“å¯†é’¥$a$çš„ã€‚åŒæ—¶åœ¨ç»Ÿè®¡æ„ä¹‰ä¸Šï¼Œæ¨¡æ‹Ÿå™¨ä¸­äº¤äº’çš„è¾“å‡ºåˆ†å¸ƒå’ŒçœŸå®Proverå’ŒVerifieräº¤äº’çš„è¾“å‡ºåˆ†å¸ƒæ˜¯ä¸€æ ·çš„ã€‚é‚£ä¹ˆç”±äºæ¨¡æ‹Ÿå™¨ä¸­æ ¹æœ¬æ²¡æœ‰çŸ¥è¯†ï¼Œä¹Ÿå°±è¯æ˜äº†é›¶çŸ¥è¯†ã€‚

é‚£ä¹ˆå¦‚ä½•åœ¨æ¨¡æ‹Ÿå™¨ä¸­è®©Proverè¯´æœVerifierå‘¢ï¼Ÿä¸Šè¶…èƒ½åŠ›â€”â€”æ—¶å…‰æœºå™¨ï¼Proverå…ˆå‘ä¸€ä¸ªåˆå§‹å€¼$g^{k_1}$éª—å–åˆ°Verifierçš„éšæœºæ•°$c$ï¼Œå›æº¯Verifierï¼Œè®©å®ƒå‘é€éšæœºæ•°$z$ï¼Œè¿›è¡Œä¸€äº›è®¡ç®—å¾—åˆ°åˆå§‹å€¼ï¼Œå½“Verifierå‘èµ·éšæœºæŒ‘æˆ˜$c$æ—¶ï¼ŒProverè¾“å‡º$z$å°±èƒ½è®©Verifierç›¸ä¿¡ProverçŸ¥é“å¯†é’¥$a$ï¼Œå®é™…ä¸ŠProverä¸çŸ¥é“å¯†é’¥$a$ã€‚

ä¸Šé¢çš„è¿‡ç¨‹éƒ½æ˜¯äº¤äº’çš„ï¼Œè½¬æ¢æˆéäº¤äº’é›¶çŸ¥è¯†è¯æ˜çš„ä¸€ä¸ªæ–¹å¼æ˜¯ç”¨å¯é çš„å“ˆå¸Œå‡½æ•°æ¥å‘èµ·éšæœºæŒ‘æˆ˜ã€‚

å¥½çš„ï¼ä¸‹é¢å¼€å§‹è¾¹è¯»åšå®¢æ–‡ç« è¾¹åšç¬”è®°ã€‚ğŸ‘‡

*This post is the second in a two-part series on zero-knowledge proofs.Â [Click here](https://blog.cryptographyengineering.com/2014/11/zero-knowledge-proofs-illustrated-primer.html)Â to readÂ Part 1.*

![Untitled](/img/2022-11-30-Zero-Knowledge-Proofs-An-illustrated-primer-Part2/Untitled.png)

In this post Iâ€™m going to continue the short, (relatively) non-technical overview of zero knowledge proofs that I started a couple of years ago. Yes, that was a very long time! If you didnâ€™t catch the first post, now would be anÂ [excellent time to go read it](https://blog.cryptographyengineering.com/2014/11/zero-knowledge-proofs-illustrated-primer.html).

Before we go much further, a bit of a warning. While this series is still intended as a high-level overview, at a certain point itâ€™s necessary to dig a bit deeper into some specific algorithms. So you should expect this post to get a bit wonkier than the last.

### **A quick recap, and a bit more on Zero Knowledge(ness)**

First, a brief refresher.

In the last post we defined a zero knowledge proof as an interaction between two computer programs (or Turing machines) â€” respectively called a Prover and a Verifier â€” where the Prover works to convince the Verifier that some mathematical statement is true. We also covered a specific example:Â a clever protocol byÂ [Goldreich, Micali and Wigderson](http://users.softlab.ece.ntua.gr/~dvitin/zk/GMW91.pdf)Â that allows us to prove, in zero knowledge, that a graph possessesÂ aÂ [three-coloring](http://en.wikipedia.org/wiki/Graph_coloring).

In the course of that discussion, we described three critical properties that any zero knowledge proof must satisfy:

- **Completeness**:Â If the Prover is honest, then she will eventually convince the Verifier.
- **Soundness:**Â The Prover can only convince the Verifier if the statement is true.
- **Zero-knowledge(ness):**Â *The Verifier learns no information beyond the fact that the statement is true.*

The real challenge turns out to be finding a way to formally define the last property. How do you state that a Verifier learnsÂ *nothing*Â beyond the truth of a statement?

In caseÂ you didnâ€™t read theÂ [previous post](https://blog.cryptographyengineering.com/2014/11/27/zero-knowledge-proofs-illustrated-primer/)Â â€” the answer to this question came from Goldwasser, Micali and Rackoff, and itâ€™s very cool. What they argued is that a protocol can be provenÂ *zero knowledge*Â if for every possible Verifier, you can demonstrate the existence of an algorithm called a â€˜Simulatorâ€™, and show that this algorithm has some very special properties.

From a purely mechanical perspective, the Simulator is like a special kind of Prover. However, unlike a real Prover â€” which starts with some special knowledge that allows it to prove the truth of a statement â€” the SimulatorÂ *gets no special knowledge at all.**Â Nonetheless, the Simulator (or Simulators) must be able to â€˜foolâ€™ every Verifier into believing that the statement is true, while producing a transcript thatâ€™s statistically identical top (or indistinguishable from) the output of a real Prover.

ä¸Šé¢å…³äºæ¨¡æ‹Ÿå™¨çš„å™è¿°æ¯”è¾ƒé‡è¦ã€‚å¯ä»¥å°†æ¨¡æ‹Ÿå™¨çœ‹ä½œæ˜¯ç‰¹æ®Šçš„ä¸€ç§Proverã€‚æ¨¡æ‹Ÿå™¨å¿…é¡»å¯ä»¥éª—è¿‡ä»»ä½•çš„Verifierç›¸ä¿¡å‘½é¢˜æ˜¯çœŸçš„ï¼Œè€Œä¸”æ¨¡æ‹Ÿå™¨äº§ç”Ÿçš„ç»“æœå’Œä¸ä¸€ä¸ªçœŸå®çš„Proveräº¤äº’å¾—åˆ°çš„ç»“æœåœ¨ç»Ÿè®¡ä¸Šæ˜¯ä¸å¯åŒºåˆ†çš„ã€‚

The logic here flows pretty cleanly: sinceÂ Simulator has no â€˜knowledgeâ€™ to extract in the first place, then clearly a VerifierÂ *canâ€™t*Â obtain any meaningful amount of information after interacting with it. Moreover, ifÂ the transcript of the interaction is distributed identically to a real protocol run with a normal Prover, then the VerifierÂ *canâ€™t*Â do better against the real prover than it can do against the Simulator. (If the VerifierÂ *could*Â do better, then that would imply that the distributions were not statistically identical.) Ergo, the Verifier canâ€™t extract useful information from the real protocol run.

This is incredibly wonky, and worse, it seems contradictory! Weâ€™re asking that a protocol be bothÂ *sound*Â â€” meaning that a bogusï¼ˆè™šå‡çš„ï¼‰ Prover canâ€™t trick some Verifier into accepting a statement unless it has special knowledge allowing it to prove the statement â€” but weâ€™re also asking for the existence of an algorithm (the simulator) that can literally cheat. Clearly both properties canâ€™t hold at the same time.

The solution to this problem is that both propertiesÂ *donâ€™t*Â hold at the same time.

To build our simulator, weâ€™re allowed to do things to the Verifier that would never happen in the real world. The example that I gave in the previous post was to use a â€˜time machineâ€™ â€” that is, our â€˜Simulatorâ€™ can rewind the Verifier programâ€™s execution in order to â€˜foolâ€™ it. Thus, in a world where we can wind the Verifier back in time, itâ€™s easy to show that a Simulator exists. In the real world, of course it doesnâ€™t. This â€˜trickâ€™ gets us around the contradiction.

çœ‹ä¼¼æ¨¡æ‹Ÿå™¨æ²¡æœ‰çŸ¥è¯†ä¹Ÿèƒ½éª—è¿‡Verifierå’ŒProveré™¤éæœ‰çŸ¥è¯†æ‰èƒ½é€šè¿‡Verifierçš„æµ‹éªŒæ˜¯çŸ›ç›¾çš„ï¼Œä½†å…¶å®è¿™ä¸¤ä¸ªä¸æ˜¯åŒæ—¶æˆç«‹çš„ã€‚æ¨¡æ‹Ÿå™¨æœ‰ä¸€äº›çœŸå®ä¸–ç•Œæ²¡æœ‰çš„è¶…èƒ½åŠ›ï¼Œæ¯”å¦‚è¯´æ—¶é—´æœºå™¨ï¼Œè¿™æ ·æ¨¡æ‹Ÿå™¨æ˜¯å¯ä»¥éª—è¿‡Verifierçš„ã€‚

As a last reminder, to illustrate all of these ideas, we covered one of the first general zero knowledge proofs, devised byÂ [Goldreich, Micali and Wigderson](http://people.csail.mit.edu/silvio/Selected%20Scientific%20Papers/Zero%20Knowledge/Proofs_That_Yield_Nothing_But_Their_Validity_or_All_Languages_in_NP_Have_Zero-Knowledge_Proof_Systems.pdf)Â (GMW). That protocol allowed us to prove, in zero knowledge, that a graph supports aÂ [three-coloring](http://en.wikipedia.org/wiki/Graph_coloring). Of course, proving three colorings isnâ€™t terribly interesting. The real significance of the GMW result is theoretical. Since graph three coloring is known to be in the complexity classÂ [NP-complete](http://en.wikipedia.org/wiki/NP-complete), the GMW protocol can be used to proveÂ *any statement*Â in the classÂ [NP](http://en.wikipedia.org/wiki/NP_%28complexity%29). And thatâ€™s quite powerful.

Let me elaborate slightly on what that means:

1. If there existsÂ *any*Â [decision problem](http://en.wikipedia.org/wiki/Decision_problem)Â (that is, a problem with a yes/no answer) whose witness (solution) can be verified in polynomial time, then:
2. We can prove that said solution exists byÂ *(1)*Â [translating the problem into an instance of the graph three-coloring problem](https://www.cs.cmu.edu/~ckingsf/bioinfo-lectures/sat.pdf), andÂ *(2)*Â running the GMW protocol.*

This amazing result gives us interactive zero knowledge proofs forÂ *every statement in NP.*Â TheÂ only problem is that itâ€™s almost totally unusable.

æˆ‘ä»¬çŸ¥é“GMWä¸­çš„å›¾ä¸‰è‰²é—®é¢˜æ˜¯NPCé—®é¢˜ï¼Œè€ŒNPé—®é¢˜å¯ä»¥å½’çº¦æˆå›¾ä¸‰è‰²é—®é¢˜ï¼Œç„¶åå¯ä»¥ç”¨GMWåè®®æ¥è¿›è¡Œé›¶çŸ¥è¯†è¯æ˜ã€‚å”¯ä¸€çš„é—®é¢˜æ˜¯è¿™æ˜¯ä¸å®ç”¨çš„ã€‚

### **From theory into practice**

If youâ€™re of a practical mindset, youâ€™re probably shaking your head at all this talk of ZK proofs. Thatâ€™s because actuallyÂ *using this approach*Â would be an insanely expensive and stupid thing to do. Most likely youâ€™d first represent your input problem as aÂ [boolean circuit](http://en.wikipedia.org/wiki/Boolean_circuit)Â where the circuit isÂ [satisfied](http://en.wikipedia.org/wiki/Circuit_satisfiability_problem)Â if and only if you know the correct input. Then youâ€™d have to translate your circuit into a graph, resulting in some further blowup. Finally youâ€™d need to run the GMW protocol, which is damned expensive all by itself.

So in practice nobody does this. Itâ€™s really considered a â€˜feasibilityâ€™ï¼ˆå¯è¡Œæ€§ï¼‰ result. Once you show that something is possible, the next step is to make it efficient.

But we do use zero knowledge proofs, almost every day. In this post Iâ€™m going to spend some time talking about the moreÂ *practical*Â ZK proofs that we actually use. To do that I just need give just a tiny bit of extra background.

### **Proofs vs. Proofs of Knowledge**

Before we go on, thereâ€™s one more concept we need to cover. Specifically, we need to discussÂ *what precisely weâ€™re proving*Â when we conductï¼ˆæ‰§è¡Œï¼‰ a zero knowledge proof*.*Let me explain. At a high level, there are two kinds of statement you might want to prove in zero knowledge. Roughly speaking, these break up as follows.

> **Statements about â€œfactsâ€.**Â For example, I might wish to prove thatÂ â€œa specific graph has a three coloringâ€ or â€œsome numberÂ NÂ is in the set of composite numbersâ€œ.Â Each of these is a statement about some intrinsic property of the universe.
> 

> **Statements about my personal knowledge.**Â Alternatively, I might wish to prove that IÂ knowÂ some piece information. Examples of this kind of statement include: â€œIÂ knowÂ a three coloring for this graphâ€, or â€œIÂ knowÂ the factorization ofÂ Nâ€.Â These go beyond merely proving that a fact is true, and actually rely on what the Prover knows.
> 

é™ˆè¿°çš„å‘½é¢˜æœ‰ä¸¤ç§ï¼Œä¸€ç§æ˜¯äº‹å®ï¼Œä¸€ç§æ˜¯ä¸ªäººçš„çŸ¥è¯†ã€‚åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œä¸»è¦å…³æ³¨åœ¨ç¬¬äºŒç§å‘½é¢˜ã€‚

Itâ€™s important to recognize that thereâ€™s a big difference between these two kinds of statements! For example, it may be possible to prove that a numberÂ *N*Â is compositeÂ *even if you donâ€™t know the full factorization.*Â So merely proving the first statement isÂ *not*Â equivalent to proving the second one.

The second class of proof is known as a â€œproof of knowledgeâ€. It turns out to be extremely useful for proving a variety of statements that we use in real life. In this post, weâ€™ll mostly be focusing on this kind of proof.

### **The Schnorr identification protocol**

Now that weâ€™ve covered some of the required background, itâ€™s helpful to move on to a specific and very useful proof of knowledge that was invented by Claus-Peter Schnorr in the 1980s. At first glance, the Schnorr protocol may seem a bit odd, but in fact itâ€™s the basis of many of our modern signature schemes today.

Schnorr wasnâ€™t really concerned with digital signatures, however. His concern was withÂ *identification.*Â Specifically, letâ€™s imagine that Alice has published her public key to the world, and later on wants to prove that she knows the secret key corresponding to that public key. This is the exact problem that we encounter in real-world protocols such as public-key SSH, so it turns out to be well-motivated.

Schnorr began with the assumption that the public key would be of a very specific format. Specifically, letÂ *p*Â be some prime number, and letÂ *g*Â be aÂ [generator](http://en.wikipedia.org/wiki/Generating_set_of_a_group)Â of aÂ [cyclic group](http://en.wikipedia.org/wiki/Cyclic_group)ï¼ˆå¾ªç¯ç¾¤ï¼‰Â of prime-orderÂ *q*. To generate a keypair, Alice would first pick a random integerÂ *a*Â between 1 andÂ *q*, and then compute the keypair as:

> $PK_A=g^a\mod p,SK_A = a$
> 

(If youâ€™ve been around the block a time or two, youâ€™ll probably notice that this is the same type of key used forÂ [Diffie-Hellman](http://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange)Â and theÂ [DSA signing](http://en.wikipedia.org/wiki/Digital_Signature_Algorithm)Â algorithm. Thatâ€™s not a coincidence, and it makes this protocol very useful.)

Alice keeps her secret key to herself, but sheâ€™s free to publish her public key to the world. Later on, when she wants to proveÂ *knowledge*Â of her secret key, she conducts the following simple interactive protocol with Bob:

![Untitled](/img/2022-11-30-Zero-Knowledge-Proofs-An-illustrated-primer-Part2/Untitled%201.png)

Thereâ€™s a lot going on in here, so letâ€™s take a minute to unpack things.

First off, we should ask ourselves if the protocol isÂ *complete.*Â This is usually the easiest property to verify: if Alice performs the protocol honestly, should Bob be satisfied at the end of it? In this case, completeness is pretty easy to see just by doing a bit of substitution:

![Untitled](/img/2022-11-30-Zero-Knowledge-Proofs-An-illustrated-primer-Part2/Untitled%202.png)

æ³¨æ„ï¼Œç”±äºé€‰å–çš„$k \in \{ 1, \dots, q \}$ï¼Œå› æ­¤$k\mod q = k$ã€‚

è¿™é‡Œè¯æ˜äº†å®Œå¤‡æ€§ï¼šè¯šå®çš„Aliceæ˜¯èƒ½å¤Ÿè¯´æœBobçš„ã€‚

### **Proving soundness**

The harder property isÂ *soundness.*Â Mainly because we donâ€™t yet have a good definition of what it means for a proof of knowledge to beÂ *sound.*Â Remember that what we want to show is the following:

> If Alice successfully convinces Bob, thenÂ she must knowÂ the secret keyÂ a.
> 

å¯é æ€§ï¼šå¦‚æœAliceèƒ½å¤ŸæˆåŠŸè®©Bobä¿¡æœï¼Œé‚£ä¹ˆå¥¹ä¸€å®šçŸ¥é“å¯†é’¥$a$ã€‚ä¹Ÿå°±æ˜¯è¯´å¦‚æœAliceä¸æ˜¯è¯šå®çš„ï¼Œå¥¹ä¸çŸ¥é“å¯†é’¥$a$çš„è¯ï¼Œé‚£ä¹ˆå¥¹è‚¯å®šä¸èƒ½è¯´æœBobã€‚

Itâ€™s easy to look at the equations above and try to convince yourself that Aliceâ€™s only way to cheat the protocol is to knowÂ *a*. But thatâ€™s hardly a proof.

When it comes to demonstrating the soundness of a proof of knowledge, we have a really nice formal approach. Just as with the Simulator we discussed above, we need to demonstrate the existence of a special algorithm. This algorithm is called aÂ ***knowledge extractor***, and it does exactly what it claims to. A knowledge extractor (or just â€˜Extractorâ€™ for short) is a special type of Verifier that interacts with a Prover, and â€” if the Prover succeeds in completing the proof â€” the Extractor should be able to extract the Proverâ€™s original secret.

æƒ³è¦è¯æ˜å¯é æ€§ï¼Œå€ŸåŠ©äºçŸ¥è¯†æå–å™¨æ¥è¯æ˜ã€‚ä¸€ä¸ªçŸ¥è¯†æå–å™¨æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„Verifierï¼Œå®ƒå’ŒProverè¿›è¡Œäº¤äº’ï¼Œå¦‚æœProverèƒ½æˆåŠŸé€šè¿‡è¯æ˜ï¼Œé‚£ä¹ˆæå–å™¨å¯ä»¥æå–åˆ°ProveråŸæ¥çš„å¯†ç ã€‚

And this answers our question above. To proveÂ *soundness*Â for a proof of knowledge, we must show that an Extractor exists for every possible Prover.

ä¸ºäº†è¯æ˜å¯é æ€§ï¼Œæˆ‘ä»¬ç°åœ¨å¿…é¡»è¯æ˜å¯¹äºæ¯ä¸€ä¸ªå¯èƒ½çš„Proverï¼Œéƒ½å­˜åœ¨è¿™æ ·ä¸€ä¸ªæå–å™¨ã€‚ç»“åˆä¸Šé¢æåˆ°çš„å¯é æ€§é™ˆè¿°ï¼Œå¦‚æœAliceèƒ½å¤ŸæˆåŠŸè®©Bobä¿¡æœï¼Œé‚£ä¹ˆå¥¹ä¸€å®šçŸ¥é“å¯†é’¥$a$ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœå¯¹äºæ¯ä¸€ä¸ªå¯èƒ½è®©Bobä¿¡æœçš„Aliceï¼Œå¦‚æœå­˜åœ¨ä¸€ä¸ªçŸ¥è¯†æå–å™¨æ¥ä¸Aliceäº¤äº’ï¼Œèƒ½æå–åˆ°å¯†é’¥$a$ï¼Œä¸å°±è¯´æ˜äº†Aliceè‚¯å®šçŸ¥é“å¯†é’¥$a$å˜›ï¼å› æ­¤è¯æ˜äº†å¯é æ€§ã€‚

è¯æ˜é€»è¾‘æ˜¯ï¼šå¯¹æ¯ä¸€ä¸ªå¯èƒ½çš„Proverå­˜åœ¨ä¸€ä¸ªæå–å™¨ â‡’ å¦‚æœAliceèƒ½è®©Bobä¿¡æœï¼ŒAliceä¸€å®šçŸ¥é“åŸæ¥çš„ç§˜å¯†ï¼ˆå¯é æ€§ï¼‰

Of course this again seems totally contradictory to the purpose of a zero knowledge protocol â€” where weâ€™reÂ *not*Â supposed to be able to learn secrets from a Prover. Fortunately weâ€™ve already resolved this conundrum once for the case of the Simulator. Here again, we take the same approach. The Extractor isÂ *not*Â required to exist during a normal run of the protocol. We simply show that it exists if weâ€™re allowed to take special liberties with the Prover â€” in this case, weâ€™ll use â€˜rewindingâ€™ to wind back the Proverâ€™s execution and allow us to extract secrets.

å½“ç„¶è¿™çœ‹èµ·æ¥åˆå’Œé›¶çŸ¥è¯†è¯æ˜åè®®çš„ç›®çš„å†²çªäº†ï¼Œä½†æ˜¯æˆ‘ä»¬ä¾ç„¶å¯ä»¥ç”¨æ¨¡æ‹Ÿå™¨çš„æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬åªéœ€è¦è®©Proveræ‹¥æœ‰è¶…èƒ½åŠ›ï¼Œç„¶åè¿™æ ·çš„æå–å™¨æ˜¯å­˜åœ¨çš„ã€‚è¿™ä¸ªè¶…èƒ½åŠ›å¯ä»¥æ˜¯æ—¶é—´æœºå™¨ï¼Œè‚¯å®šç°å®ä¸–ç•Œä¸å­˜åœ¨æ—¶é—´æœºå™¨ï¼Œå› æ­¤ä¸ä¼šå’Œæ³„æ¼çŸ¥è¯†è¿™ä¸ªç›®çš„ç›¸å†²çªã€‚

The extractor for the Schnorr protocol is extremely clever â€” and itâ€™s also pretty simple. Letâ€™s illustrate it in terms of a protocol diagram. Alice (the Prover) is on the left, and the Extractor is on the right:

![Untitled](/img/2022-11-30-Zero-Knowledge-Proofs-An-illustrated-primer-Part2/Untitled%203.png)

The key observation here is that by rewinding Aliceâ€™s execution, the Extractor can â€˜trickâ€™ Alice into making two different proof transcripts using the sameÂ *k*. This shouldnâ€™t normally happen in a real protocol run, where Alice specifically picks a newÂ *k*Â for each execution of the protocol.

å…³é”®çš„ä¸€ç‚¹æ˜¯é€šè¿‡è®©Aliceé‡æ–°æ‰§è¡Œåˆ°ç¬¬2æ­¥ï¼Œæå–å™¨å¯ä»¥éª—Aliceç»™ä¸¤ä¸ªä¸åŒçš„è¯æ˜ä½†æ˜¯ç”¨åŒä¸€ä¸ª$k$ã€‚åœ¨å®é™…çš„åè®®è¿è¡Œä¸­ï¼Œè¿™æ˜¯é€šå¸¸ä¸åº”è¯¥å‘ç”Ÿçš„ï¼ŒAliceä¼šåœ¨åè®®æ¯æ¬¡æ‰§è¡Œçš„æ—¶å€™ç‰¹åˆ«é€‰æ‹©ä¸€ä¸ªæ–°çš„$k$ã€‚

If the Extractor can trick Alice into doing this, then he can solve the following simple equation to recover Aliceâ€™s secret:

![Untitled](/img/2022-11-30-Zero-Knowledge-Proofs-An-illustrated-primer-Part2/Untitled%204.png)

å¦‚æœæå–å™¨èƒ½å¤Ÿéª—Aliceè¿™æ ·åšçš„è¯ï¼Œæå–å™¨æ˜¯å¯ä»¥æå–åˆ°Aliceæ‹¥æœ‰çš„å¯†é’¥$a$ã€‚

æ¨å¯¼çš„è¯¦ç»†è¿‡ç¨‹ï¼š

$$
\begin{array}{l} 
  \frac{s_1 - s_2}{c_1 - c_2} \mod q & \\\ 
  \quad = \frac{((ac_1+k) \mod q)-((ac_2 + k) \mod q)}{c_1 - c_2} \mod q \\\
  \quad = \frac{(ac_1+k)-(ac_2 + k) }{c_1 - c_2} \mod q \\\
  \quad = \frac{ac_1 - ac_2 }{c_1 - c_2} \mod q \\\
  \quad = a \mod q
\end{array}  
$$

Itâ€™s worth taking a moment right now to note that thisÂ *also*Â implies a serious vulnerabilityï¼ˆæ¼æ´ï¼‰ in bad implementations of the Schnorr protocol. If you everÂ *accidentally*Â use the sameÂ *k*Â for two different runs of the protocol, an attacker may be able to recover your secret key! This can happen if you use a bad random number generator.

éœ€è¦æ³¨æ„Schnorr protocolåœ¨å®é™…ä¸­å¯èƒ½å‡ºç°çš„æ¼æ´ï¼Œé‚£å°±æ˜¯åœ¨ä¸åŒè¿è¡Œä¸­ä½¿ç”¨ç›¸åŒçš„$k$ï¼Œå› æ­¤è¦é€‰æ‹©å¥½çš„éšæœºç”Ÿæˆå™¨ã€‚

Indeed, those with a bit more experience will notice that this is similar to aÂ *[real*Â attack on systems (with bad random number generators)](https://www.schneier.com/blog/archives/2011/01/sony_ps3_securi.html)Â that implement ECDSA or DSA signatures! This is also not a coincidence. The (EC)DSA signature family is based on Schnorr. Ironicallyï¼ˆè®½åˆºåœ°ï¼‰, the developers of DSA managed to retain this vulnerability of the Schorr family of protocols whileÂ *at the same time*Â ditching the security proof that makes Schnorr so nice.

### **Proving zero-knowledge(ness) against an honest Verifier**

Having demonstratedï¼ˆè¯æ˜ï¼‰ that Schnorr signatures are complete and sound, it remains only to prove that theyâ€™re â€˜*zero knowledgeâ€™*. Remember that to do this, normally we require a Simulator that can interact with any possible Verifier and produce a â€˜simulatedâ€™ transcript of the proof, even if the Simulator doesnâ€™t know the secret itâ€™s proving it knows.

ä¸ºäº†è¯æ˜â€œé›¶çŸ¥è¯†â€ï¼Œä¸€èˆ¬è¦æ±‚æœ‰ä¸€ä¸ªå¯ä»¥å’Œæ‰€æœ‰å¯èƒ½çš„Verifierçš„æ¨¡æ‹Ÿå™¨ï¼Œè¾“å‡ºè¯æ˜çš„ç»“æœï¼Œè€Œæ¨¡æ‹Ÿå™¨ç”šè‡³ä¸çŸ¥é“å®ƒè¦è¯æ˜çš„çŸ¥è¯†ã€‚

The standard Schnorr protocol does not have such a Simulator, for reasons weâ€™ll get into in a second. Instead, to make the proof work we need to make a special assumption. Specifically, the Verifier needs to be â€˜honestâ€™. That is, we need to make the special assumption that it will run its part of the protocol correctly â€” namely, that it will pick its challenge â€œ*c*â€Â using only its random number generator,Â *and will not choose this value based on any input we provide it*. As long as it does this, we can construct a Simulator.

æ ‡å‡†çš„Schnorråè®®æ˜¯æ²¡æœ‰è¿™æ ·çš„æ¨¡æ‹Ÿå™¨çš„ã€‚è¿™é‡Œè¦åšä¸€ä¸ªå‡è®¾ï¼ŒVerifieréœ€è¦æ˜¯â€œè¯šå®çš„â€ã€‚æˆ‘ä»¬éœ€è¦å‡è®¾åœ¨Verifieré€‰æ‹©æŒ‘æˆ˜â€œcâ€æ—¶ï¼Œåªç”¨åˆ°ä¸€ä¸ªéšæœºæ•°ç”Ÿæˆå™¨ï¼Œè€Œä¸ä¼šé€‰æ‹©é‚£äº›åŸºäºä»»ä½•æˆ‘ä»¬æä¾›çš„è¾“å…¥ç”Ÿæˆçš„å€¼ã€‚

Hereâ€™s how the Simulator works.

Letâ€™s say we are trying to prove knowledge of a secret $a$ for some public key $g^a \mod p$ *â€”* but we donâ€™t actually know the value*.* Our Simulator assumes that the Verifier will choose some value $c$ as its challenge, and moreover, it knows that the honest Verifier will choose the value $c$    only  based on its random number generator â€” and not based on any inputs the Prover has provided.

1. First, output some initialÂ Â $g^{k_1}$ as the Proverâ€™s first message*,*Â and find out what challenge $c$Â Â the Verifier chooses.
2. *Rewind the Verifier*, and pick a random integerÂ $z$Â in the rangeÂ $\{ 0, \cdots, q-1 \}$*.*
3. ComputeÂ $g^{k_2} = g^z * g^{a(-c)}$Â **and outputÂ $g^{k_2}$Â as the Proverâ€™s new initial message.
4. When the Verifier challenges onÂ $c$Â again, outputÂ $z$.

Notice that the transcript $g^k,c,z$ will verify correctly as a perfectly valid, well-distributed proof of knowledge of the value $a$. The Verifier will accept this output as a valid proof of knowledge of $a$, even though the Simulator does not know $a$ in the first place!

è¯¦ç»†çš„è¿‡ç¨‹å¦‚ä¸‹ï¼š

![Untitled](/img/2022-11-30-Zero-Knowledge-Proofs-An-illustrated-primer-Part2/Untitled%205.png)

What this proves is thatÂ *if we can rewind a Verifier*, then (just as in the first post in this series) we can always trick the Verifier into believing we have knowledge of a value, even when we donâ€™t. And since the statistical distribution of our protocol is identical to the real protocol, this means that our protocol must be zero knowledge â€” against an honest Verifier.

åœ¨æ¨¡æ‹Ÿå™¨ä¸–ç•Œé‡Œï¼Œæˆ‘ä»¬å¯ä»¥å›æº¯Verifierï¼Œè®©è¯šå®çš„Verifierç›¸ä¿¡æˆ‘ä»¬æ˜¯çŸ¥é“å¯†é’¥$a$çš„ï¼Œä½†å…¶å®æˆ‘ä»¬æ ¹æœ¬ä¸çŸ¥é“$a$æ—¶å¤šå°‘ã€‚ç”±äºåœ¨ç»Ÿè®¡åˆ†å¸ƒä¸Šæˆ‘ä»¬çš„åè®®å’ŒçœŸå®çš„åè®®æ˜¯ä¸€æ ·çš„ï¼Œé‚£ä¹ˆå¯¹äºè¯šå®çš„Verifierï¼Œæˆ‘ä»¬çš„åè®®ä¸€å®šæ˜¯é›¶çŸ¥è¯†çš„ã€‚

### **From interactive toÂ *non-interactive***

So far weâ€™ve shown how to use the Schnorr protocol to *interactively prove knowledge* of a secret key $a$ that corresponds to a public key $g^a$. This is an incredibly useful protocol, but it only works if our Verifier is online and willing to interact with us.

An obvious question is whether we can make this protocol workÂ without interaction. Specifically, can I make a proof that I can send you without you even being online. Such a proof is called aÂ [non-interactive zero knowledge proof](https://en.wikipedia.org/wiki/Non-interactive_zero-knowledge_proof)Â (NIZK).Â Turning Schnorr into a non-interactive proof seems initially quiteÂ difficult â€” since the protocol fundamentally relies on the Verifier picking a random challenge. Fortunately there is a clever trick we can use.

This techniqueÂ wasÂ developed by Fiat and Shamir in the 1980s. What they observed was thatÂ *if you have a decent hash function lying around,*Â you can convert an interactive protocol into a non-interactive one by simply using the hash function to pick the challenge.

æ€ä¹ˆå°†äº¤äº’å¼é›¶çŸ¥è¯†è¯æ˜è½¬æ¢æˆéäº¤äº’å¼é›¶çŸ¥è¯†è¯æ˜å‘¢ï¼Ÿè½¬æ¢çš„éš¾ç‚¹åœ¨äºVerifieréœ€è¦é€‰æ‹©ä¸€ä¸ªéšæœºçš„æŒ‘æˆ˜ï¼Œä¸€ä¸ªè§£å†³æ–¹æ³•æ˜¯ä½¿ç”¨å¯é çš„å“ˆå¸Œå‡½æ•°æ¥é€‰æ‹©è¿™ä¸ªæŒ‘æˆ˜ã€‚

Specifically, the revised protocol for proving knowledge of $a$ with respect to a public key $g^k$ looks like this:

1. The Prover picksÂ Â $g^k$ (just as in the interactiveÂ protocol).
2. Now, the prover computesÂ the challenge as $c = H(g^k||M)$ whereÂ $H()$Â is a hash function, and $M$ is an (optional) and arbitary message string.
3. ComputeÂ $ac+k \mod q$Â (just as in the interactive protocol).

The upshot here is that the hash function is picking the challenge $c$ without any interaction with the Verifier. In principle, if the hash function is â€œstrong enoughâ€ (meaning, itâ€™s a [random oracle](https://blog.cryptographyengineering.com/2011/09/29/what-is-random-oracle-model-and-why-3/)) then the result is a completely non-interactive proof of knowledge of the value $a$ that the Prover can send to the Verifier. The proof of this is relatively straightforward.

The particularly neat thing about this protocol is that it isnâ€™t just a proof of knowledge, itâ€™s also a *signature scheme.* That is, if you put a message into the (optional) value $M$, you obtain a signature on $M$, whichÂ can only be produced by someone who knows the secret key $a$. The resulting protocol is called the Schnorr signature scheme, and itâ€™s the basis of real-world protocols like [EdDSA](https://en.wikipedia.org/wiki/EdDSA).

è¿™ä¸ªåè®®ä¸ä»…ä»…æ˜¯çŸ¥è¯†çš„è¯æ˜ï¼Œä¹Ÿæ˜¯ä¸€ç§ç­¾åæ–¹æ¡ˆã€‚

### **Phew.**

Yes, this has been a long post and thereâ€™s probably a lot more to be said. Hopefully there will be more time for that in a third post â€” which should only take me another three years.

*Notes:*

- In this definition, itâ€™s necessary that the statement be literally true.